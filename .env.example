DEBUG=true
API_V1_STR=/api/v1
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:70b
DEFAULT_TEMPERATURE=0.7
MAX_TOKENS=131072
MAX_CONTEXT_LENGTH=131072
MODEL_EMBEDDING_SIZE=8192

# Phase 2 - Redis Configuration (currently not in use)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
CACHE_TTL=3600
